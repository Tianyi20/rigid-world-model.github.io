<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="One-Shot Real-to-Sim via End-to-End Differentiable Simulation and Rendering.">
  <meta name="keywords" content="differentiable simulation, rigid body simulation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>One-Shot Real-to-Sim via End-to-End Differentiable Simulation and Rendering.</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>




<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">One-Shot Real-to-Sim via End-to-End Differentiable Simulation and Rendering</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://yifanzhu95.github.io/">Yifan Zhu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://tianyi20.github.io/">Tianyi Xiang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://engineering.yale.edu/research-and-faculty/faculty-directory/aaron-m-dollar">Aaron M. Dollar</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://dyingbrain.github.io/">Zherong Pan</a><sup>2</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Yale University,</span>
            <span class="author-block"><sup>2</sup>Independent researcher</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://yifanzhu95.github.io/files/RAL2024_SimFromVid.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/pdf/2412.00259"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/yifanzhu95/RigidWorldModel"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>



<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>


             Identifying predictive world models for robots from sparse online observations is essential for robot task planning and execution in novel environments. 
             However, existing methods that leverage differentiable programming to identify world models are incapable of 
             jointly optimizing the geometry, appearance, and physical properties of the scene. 
             In this work, we introduce a novel rigid object representation that allows the joint identification of these properties. Our method employs a novel differentiable point-based geometry representation coupled with a grid-based appearance field, which allows differentiable object collision detection and rendering. 
             Combined with a differentiable physical simulator, we achieve end-to-end optimization of world models or rigid objects, given the sparse visual and tactile observations of a physical motion sequence. Through a series of \revise{world model identification} tasks in simulated and real environments, we show that our method can learn both simulation- and rendering-ready rigid world models from only one robot action sequence. 
            
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <div class="columns is-centered">
      <div class="column is-two-thirds has-text-centered">
        <figure class="image is-16by">
          <img src="./static/images/spotlight.jpg" alt="spotlight">
        </figure>
      </div>
    </div>

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/MrKrnHhk8IA?rel=0&amp;showinfo=0"
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div>
  </div> -->
</section>

<!-- Simulation Experiments Header -->
<div class="section-header has-text-centered mb-5">
  <h2 class="title">Simulation Experiments</h2>
  <p class="subtitle">GT data generated by <strong>PyBullet</strong>. All videos are 1/10x.</p>

</div>

<!-- Simulations Section (Vertical Stack) -->
<section id="simulations" class="hero teaser">
  <div class="container is-max-desktop">
    <!-- Simulation 1: Bleach -->
    <div class="video-item mb-6">
      <video id="sim-bleach" autoplay muted loop playsinline style="width:100%; height:auto;">
        <source src="static/website_videos/simulation_experiments/bleach/bleach_combo_crop.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      <h2 class="subtitle has-text-centered mt-2">
        <span class="dnerf">Simulation 1: Bleach</span>
      </h2>
    </div>

    <!-- Simulation 2: Mustard -->
    <div class="video-item mb-6">
      <video id="sim-mustard" autoplay muted loop playsinline style="width:100%; height:auto;">
        <source src="static/website_videos/simulation_experiments/mustard/mustard_combo_crop.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      <h2 class="subtitle has-text-centered mt-2">
        <span class="dnerf">Simulation 2: Mustard</span>
      </h2>
    </div>

    <!-- Simulation 3: Sugar -->
    <div class="video-item mb-6">
      <video id="sim-sugar" autoplay muted loop playsinline style="width:100%; height:auto;">
        <source src="static/website_videos/simulation_experiments/sugar/sugar_combo_crop.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      <h2 class="subtitle has-text-centered mt-2">
        <span class="dnerf">Simulation 3: Sugar</span>
      </h2>
    </div>
  </div>
</section>

<!-- Divider Between Sections -->
<hr class="divider my-6">

<!-- Real-World Experiments Header -->
<div class="section-header has-text-centered mb-5">
  <h2 class="title">Real-World Experiments</h2>
  <p class="subtitle"> The end-effector is represented as a <strong> blue sphere </strong>. All videos are 1/3x.</p>

</div>

<!-- Real-World Experiments Section (Vertical Stack) -->
<section id="real-experiments" class="hero teaser">
  <div class="container is-max-desktop">
    <!-- Real 1: Drill -->
    <div class="video-item mb-6">
      <video id="real-drill" autoplay muted loop playsinline style="width:100%; height:auto;">
        <source src="static/website_videos/real_experiments/drill/real_drill_combo_crop.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      <h2 class="subtitle has-text-centered mt-2">
        <span class="dnerf">Real Experiment 1: Drill</span>
      </h2>
    </div>

    <!-- Real 2: Mustard -->
    <div class="video-item mb-6">
      <video id="real-mustard" autoplay muted loop playsinline style="width:100%; height:auto;">
        <source src="static/website_videos/real_experiments/mustard/real_mustard_combo_crop.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      <h2 class="subtitle has-text-centered mt-2">
        <span class="dnerf">Real Experiment 2: Mustard</span>
      </h2>
    </div>

    <!-- Real 3: Sugar -->
    <div class="video-item mb-6">
      <video id="real-sugar" autoplay muted loop playsinline style="width:100%; height:auto;">
        <source src="static/website_videos/real_experiments/sugar/real_sugar_combo_crop.mp4" type="video/mp4">
        Your browser does not support the video tag.
      </video>
      <h2 class="subtitle has-text-centered mt-2">
        <span class="dnerf">Real Experiment 3: Sugar</span>
      </h2>
    </div>
  </div>
</section>


<!-- 
<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-steve">
          <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/steve.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-chair-tp">
          <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/chair-tp.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-shiba">
          <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/shiba.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-fullbody">
          <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/fullbody.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-blueshirt">
          <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/blueshirt.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-mask">
          <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/mask.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-coffee">
          <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/coffee.mp4"
                    type="video/mp4">
          </video>
        </div>
        <div class="item item-toby">
          <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/toby2.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->





<section class="section">
  <div class="container is-max-desktop">
    <!-- Methodology -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Methodology</h2>
      </div>
    </div>
    <div class="columns is-centered">
      <div class="column has-text-centered">
        <figure class="image">
          <img 
            src="./static/images/method.png" 
            alt="Method overview" 
            style="max-width: 100%; height: auto;">
            <p>Overview of the proposed fully differentiable pipeline for world model identification from sparse robot observations. Our object representation couples an oriented point cloud <i>P</i> and a 3D appearance grid <i>ψ</i>. Through a differentiable Poisson solver and differentiable marching cubes, the oriented point cloud is converted to an indicator grid <i>χ</i> and then a mesh, whose vertex textures are interpolated from the appearance grid <i>ψ</i>. Feeding the object mesh, physical parameters <i>M</i> and <i>μ</i>, the terrain point cloud <i>P</i><sub>t</sub>, and the robot pushing trajectory and control &lt;<i>e</i><sup>t</sup>, <i>u</i><sup>t</sup>&gt; into a differentiable rigid body simulator and renderer, the predicted scenes can be rendered. Calculating the loss against observed RGB-D images, the scene shape, appearance, and physical parameters are jointly optimized with gradient descent.</p>

        </figure>
      </div>
    </div>
    <!-- Video Placeholder -->

    <!-- /Video Placeholder -->
    <!-- /Methodology -->
  </div>
</section>





<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
              
              This site’s design and structure are built upon the Nerfies page template, generously open-sourced by the Nerfies team.
              We’re grateful for their work in making the template code available at <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
